{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import spacy\n",
    "\n",
    "from gensim import models, corpora\n",
    "from gensim import similarities\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_articles.txt', 'r', encoding='utf8') as f:\n",
    "  articles = f.read().split('@delimiter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 111425 articles\n",
    "print(len(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = 20\n",
    "NUM_PROCESSES = 6\n",
    "NUM_TOPICS = 20\n",
    "dataset = articles[:DATASET_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg',disable=['parser','ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_filter(tokenized_doc):\n",
    "    filtered_tokens = []\n",
    "\n",
    "    for token in tokenized_doc:\n",
    "        if(token.is_alpha and token.pos_ in ['NOUN','VERB','ADJ'] and token.is_punct == False and token.is_space == False and token.is_stop == False):\n",
    "            filtered_tokens.append(token.lemma_)\n",
    "    \n",
    "    # returns filtered_tokens of a particular doc object\n",
    "    return filtered_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_articles = list(map(token_filter,nlp.pipe(dataset,n_process=NUM_PROCESSES)))\n",
    "tokenized_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a Dictionary of word<-->id mappings is created\n",
    "dictionary = corpora.Dictionary(tokenized_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter out words which occur in fewer than 5 (no_below = 5) documents and more than 50% (no_above = 0.5) of the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=5,no_above=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "corpus_bow = [dictionary.doc2bow(article) for article in tokenized_articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lda_model = models.ldamodel.LdaModel(corpus=corpus_bow,\n",
    "                                     id2word=dictionary,\n",
    "                                     num_topics=NUM_TOPICS,\n",
    "                                     passes=10,\n",
    "                                     alpha='auto',\n",
    "                                     eta='auto',\n",
    "                                     random_state=1,\n",
    "                                     NUM_PROCESSES=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.save(\"lda_model.gensim\")\n",
    "dictionary.save(\"lda_dictionary.gensim\")\n",
    "corpora.MmCorpus.serialize(\"lda_corpus.mm\", corpus_bow)  # Save the corpus in Matrix Market format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_index = similarities.MatrixSimilarity(lda_model[corpus_bow], num_features=len(dictionary))\n",
    "lda_index.save(\"lda_index.sim\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_demy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
